{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHO_b0kZDAra",
        "outputId": "02d85ef9-2214-4e5b-8847-caf5b3413f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , LSTM , Dropout , Embedding , Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "BMBqWMygEyva"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/alice_in_wonderland.txt'\n",
        "file1 = open(path,'r',encoding='utf-8').read()\n",
        "file1 = file1.lower()\n",
        "file1 = file1.split('\\n')"
      ],
      "metadata": {
        "id": "mlv7lsDVFP3v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "Cgl_4Tv_FHLJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(file1)"
      ],
      "metadata": {
        "id": "xFsokFTVBXDe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "ZFidJBD9Yxit"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'total words {total_words}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOBJRAysYxvL",
        "outputId": "0017b8e1-e5bd-4f4e-f467-43c62aec77ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words 2647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GR-cuWXHCLYU",
        "outputId": "39d21231-cab8-4075-8480-4c9930800bd4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"alice's adventures in wonderland\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(['i am good'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfzcsUmpBtkY",
        "outputId": "049af781-e8df-43bc-8182-429643e617cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 250, 166]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = [10, 250, 166]"
      ],
      "metadata": {
        "id": "MEdTQhSHD2HM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for file2 in file1:\n",
        "  token_list = tokenizer.texts_to_sequences([file2])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "UKTn7kEkYx5-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(i)for i in input_sequences])"
      ],
      "metadata": {
        "id": "tI-Ru6B_YyNv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[6] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhwUDGiuYyXO",
        "outputId": "6a07112a-0ecf-4bfb-c4d6-ee5be5569478"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1490, 1491]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding = pad_sequences(input_sequences,maxlen=16,padding='pre')"
      ],
      "metadata": {
        "id": "uX4-Z3ThYyq7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ixytLX61I2EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TSe252tiWIR",
        "outputId": "56bff5aa-78fd-4549-9455-3f84a10596b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[278, 423]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVsULSLIYy7b",
        "outputId": "9013a968-f701-40e3-f09d-ab1e9d04489f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 278, 423], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-iqC5HHFS19",
        "outputId": "ce148782-4a1f-4b8e-fb12-e7b0ea7fc6cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25073, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padding[:,:-1]\n",
        "y = padding[:,-1]"
      ],
      "metadata": {
        "id": "tHNDqeDVcRD8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y,2647)"
      ],
      "metadata": {
        "id": "EjSQtcR0cRPx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SGOsqxCwIojl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=92)"
      ],
      "metadata": {
        "id": "HFNl9S-CI4ve"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrBB8IbucRab",
        "outputId": "eacfafc1-0735-40eb-d8c6-269dd6e59144"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3761, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMyTvMoKcRkz",
        "outputId": "e0281871-5b0c-4189-d854-cf258d997500"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2647"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 300, input_length=15))\n",
        "model.add(Bidirectional(LSTM(350,return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(350)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# earlystop = EarlyStopping(monitor='accuracy', min_delta=0, patience=50, verbose=1, mode='max')\n",
        "filepath=\"accuracy_nlp-next_word.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath,save_best_only=True, mode='min')"
      ],
      "metadata": {
        "id": "5yztZ8RPcRvL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp-qa3FkcR5f",
        "outputId": "0993ac67-65b4-4da6-9338-45ffa7f91a19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 300)           794100    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 700)          1822800   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 700)              2942800   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2647)              1855547   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,415,247\n",
            "Trainable params: 7,415,247\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=200, verbose=1,batch_size=1024 , callbacks=[checkpoint],validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ_QorqZcSDN",
        "outputId": "b0fe0bd6-b8f0-42da-f3a1-d8bf266ef3ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "25/25 [==============================] - 15s 206ms/step - loss: 6.4894 - accuracy: 0.0515 - val_loss: 5.9818 - val_accuracy: 0.0561\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 4s 155ms/step - loss: 5.9840 - accuracy: 0.0560 - val_loss: 5.9214 - val_accuracy: 0.0561\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 5.9268 - accuracy: 0.0599 - val_loss: 5.8222 - val_accuracy: 0.0564\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 5.7803 - accuracy: 0.0638 - val_loss: 5.6642 - val_accuracy: 0.0643\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 5.6393 - accuracy: 0.0743 - val_loss: 5.5259 - val_accuracy: 0.0787\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 5.5097 - accuracy: 0.0871 - val_loss: 5.4091 - val_accuracy: 0.0840\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 5.3984 - accuracy: 0.0931 - val_loss: 5.3029 - val_accuracy: 0.0904\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 4s 158ms/step - loss: 5.2992 - accuracy: 0.0999 - val_loss: 5.1921 - val_accuracy: 0.0968\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 4s 157ms/step - loss: 5.1915 - accuracy: 0.1137 - val_loss: 5.0904 - val_accuracy: 0.1114\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 5.0772 - accuracy: 0.1246 - val_loss: 4.9629 - val_accuracy: 0.1282\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 4.9726 - accuracy: 0.1324 - val_loss: 4.8629 - val_accuracy: 0.1409\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 4.8773 - accuracy: 0.1391 - val_loss: 4.7733 - val_accuracy: 0.1380\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 4.7949 - accuracy: 0.1459 - val_loss: 4.6758 - val_accuracy: 0.1500\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 4.7123 - accuracy: 0.1514 - val_loss: 4.5869 - val_accuracy: 0.1587\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 4.6208 - accuracy: 0.1576 - val_loss: 4.5013 - val_accuracy: 0.1651\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 4s 165ms/step - loss: 4.5327 - accuracy: 0.1644 - val_loss: 4.4223 - val_accuracy: 0.1694\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 4s 165ms/step - loss: 4.4501 - accuracy: 0.1689 - val_loss: 4.3236 - val_accuracy: 0.1771\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 4s 166ms/step - loss: 4.3650 - accuracy: 0.1746 - val_loss: 4.2257 - val_accuracy: 0.1864\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 4s 167ms/step - loss: 4.2806 - accuracy: 0.1803 - val_loss: 4.1618 - val_accuracy: 0.1880\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 4.2053 - accuracy: 0.1865 - val_loss: 4.0735 - val_accuracy: 0.1978\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 4.1327 - accuracy: 0.1892 - val_loss: 3.9980 - val_accuracy: 0.2047\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 4.0551 - accuracy: 0.1971 - val_loss: 3.9402 - val_accuracy: 0.1981\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 3.9843 - accuracy: 0.2017 - val_loss: 3.8546 - val_accuracy: 0.2042\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 3.9105 - accuracy: 0.2066 - val_loss: 3.7878 - val_accuracy: 0.2212\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 3.8474 - accuracy: 0.2119 - val_loss: 3.7198 - val_accuracy: 0.2212\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 3.7854 - accuracy: 0.2199 - val_loss: 3.6510 - val_accuracy: 0.2284\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 3.7136 - accuracy: 0.2236 - val_loss: 3.5930 - val_accuracy: 0.2327\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 3.6443 - accuracy: 0.2332 - val_loss: 3.5251 - val_accuracy: 0.2422\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 3.5870 - accuracy: 0.2376 - val_loss: 3.4808 - val_accuracy: 0.2497\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 3.5322 - accuracy: 0.2459 - val_loss: 3.4318 - val_accuracy: 0.2531\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 4s 178ms/step - loss: 3.4686 - accuracy: 0.2525 - val_loss: 3.3498 - val_accuracy: 0.2709\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 3.4020 - accuracy: 0.2623 - val_loss: 3.2913 - val_accuracy: 0.2715\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 3.3483 - accuracy: 0.2695 - val_loss: 3.2358 - val_accuracy: 0.2861\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 3.2799 - accuracy: 0.2790 - val_loss: 3.1724 - val_accuracy: 0.3012\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 3.2233 - accuracy: 0.2874 - val_loss: 3.1411 - val_accuracy: 0.2941\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 3.1693 - accuracy: 0.2975 - val_loss: 3.0644 - val_accuracy: 0.3137\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 3.1106 - accuracy: 0.3059 - val_loss: 2.9962 - val_accuracy: 0.3212\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 3.0491 - accuracy: 0.3158 - val_loss: 2.9446 - val_accuracy: 0.3302\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 5s 186ms/step - loss: 3.0020 - accuracy: 0.3247 - val_loss: 2.9007 - val_accuracy: 0.3395\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 2.9492 - accuracy: 0.3346 - val_loss: 2.8536 - val_accuracy: 0.3512\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 2.8917 - accuracy: 0.3461 - val_loss: 2.7958 - val_accuracy: 0.3563\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.8399 - accuracy: 0.3548 - val_loss: 2.7392 - val_accuracy: 0.3725\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.7852 - accuracy: 0.3647 - val_loss: 2.6636 - val_accuracy: 0.3901\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 2.7255 - accuracy: 0.3757 - val_loss: 2.6371 - val_accuracy: 0.3922\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 2.6780 - accuracy: 0.3855 - val_loss: 2.5901 - val_accuracy: 0.3946\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 2.6130 - accuracy: 0.3974 - val_loss: 2.5207 - val_accuracy: 0.4156\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 2.5654 - accuracy: 0.4085 - val_loss: 2.4836 - val_accuracy: 0.4204\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 2.5145 - accuracy: 0.4196 - val_loss: 2.4276 - val_accuracy: 0.4350\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 4s 180ms/step - loss: 2.4721 - accuracy: 0.4276 - val_loss: 2.3847 - val_accuracy: 0.4496\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.4287 - accuracy: 0.4386 - val_loss: 2.3358 - val_accuracy: 0.4549\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.3734 - accuracy: 0.4481 - val_loss: 2.2835 - val_accuracy: 0.4669\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.3224 - accuracy: 0.4605 - val_loss: 2.2536 - val_accuracy: 0.4696\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 2.2846 - accuracy: 0.4712 - val_loss: 2.1826 - val_accuracy: 0.4922\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 2.2209 - accuracy: 0.4858 - val_loss: 2.1326 - val_accuracy: 0.5041\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 2.1750 - accuracy: 0.4970 - val_loss: 2.0931 - val_accuracy: 0.5113\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 2.1392 - accuracy: 0.5020 - val_loss: 2.0637 - val_accuracy: 0.5251\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.0939 - accuracy: 0.5125 - val_loss: 2.0245 - val_accuracy: 0.5302\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 2.0515 - accuracy: 0.5248 - val_loss: 1.9676 - val_accuracy: 0.5499\n",
            "Epoch 59/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.9922 - accuracy: 0.5404 - val_loss: 1.9102 - val_accuracy: 0.5594\n",
            "Epoch 60/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 1.9465 - accuracy: 0.5479 - val_loss: 1.8701 - val_accuracy: 0.5639\n",
            "Epoch 61/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 1.9109 - accuracy: 0.5597 - val_loss: 1.8306 - val_accuracy: 0.5796\n",
            "Epoch 62/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 1.8625 - accuracy: 0.5728 - val_loss: 1.7755 - val_accuracy: 0.5935\n",
            "Epoch 63/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.8098 - accuracy: 0.5856 - val_loss: 1.7411 - val_accuracy: 0.6022\n",
            "Epoch 64/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 1.7710 - accuracy: 0.5928 - val_loss: 1.7156 - val_accuracy: 0.6131\n",
            "Epoch 65/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 1.7330 - accuracy: 0.6032 - val_loss: 1.6563 - val_accuracy: 0.6227\n",
            "Epoch 66/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.6802 - accuracy: 0.6166 - val_loss: 1.6089 - val_accuracy: 0.6379\n",
            "Epoch 67/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.6487 - accuracy: 0.6258 - val_loss: 1.5760 - val_accuracy: 0.6405\n",
            "Epoch 68/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 1.6045 - accuracy: 0.6367 - val_loss: 1.5381 - val_accuracy: 0.6586\n",
            "Epoch 69/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.5737 - accuracy: 0.6456 - val_loss: 1.5119 - val_accuracy: 0.6557\n",
            "Epoch 70/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.5442 - accuracy: 0.6539 - val_loss: 1.4718 - val_accuracy: 0.6700\n",
            "Epoch 71/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.4924 - accuracy: 0.6637 - val_loss: 1.4273 - val_accuracy: 0.6793\n",
            "Epoch 72/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.4436 - accuracy: 0.6789 - val_loss: 1.3898 - val_accuracy: 0.6940\n",
            "Epoch 73/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.4028 - accuracy: 0.6881 - val_loss: 1.3475 - val_accuracy: 0.7051\n",
            "Epoch 74/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.3665 - accuracy: 0.7012 - val_loss: 1.2986 - val_accuracy: 0.7229\n",
            "Epoch 75/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.3331 - accuracy: 0.7068 - val_loss: 1.2754 - val_accuracy: 0.7227\n",
            "Epoch 76/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 1.3125 - accuracy: 0.7123 - val_loss: 1.2763 - val_accuracy: 0.7152\n",
            "Epoch 77/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 1.2855 - accuracy: 0.7182 - val_loss: 1.2263 - val_accuracy: 0.7336\n",
            "Epoch 78/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.2445 - accuracy: 0.7288 - val_loss: 1.1857 - val_accuracy: 0.7490\n",
            "Epoch 79/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.2038 - accuracy: 0.7414 - val_loss: 1.1496 - val_accuracy: 0.7572\n",
            "Epoch 80/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.1630 - accuracy: 0.7506 - val_loss: 1.1208 - val_accuracy: 0.7713\n",
            "Epoch 81/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 1.1356 - accuracy: 0.7593 - val_loss: 1.0745 - val_accuracy: 0.7764\n",
            "Epoch 82/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.1029 - accuracy: 0.7656 - val_loss: 1.0518 - val_accuracy: 0.7814\n",
            "Epoch 83/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.0748 - accuracy: 0.7735 - val_loss: 1.0227 - val_accuracy: 0.7929\n",
            "Epoch 84/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 1.0446 - accuracy: 0.7802 - val_loss: 0.9875 - val_accuracy: 0.7955\n",
            "Epoch 85/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 1.0158 - accuracy: 0.7875 - val_loss: 0.9833 - val_accuracy: 0.7929\n",
            "Epoch 86/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.9983 - accuracy: 0.7907 - val_loss: 0.9354 - val_accuracy: 0.8112\n",
            "Epoch 87/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.9631 - accuracy: 0.7993 - val_loss: 0.9063 - val_accuracy: 0.8195\n",
            "Epoch 88/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.9292 - accuracy: 0.8070 - val_loss: 0.8819 - val_accuracy: 0.8235\n",
            "Epoch 89/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.8980 - accuracy: 0.8162 - val_loss: 0.8447 - val_accuracy: 0.8336\n",
            "Epoch 90/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.8709 - accuracy: 0.8210 - val_loss: 0.8286 - val_accuracy: 0.8325\n",
            "Epoch 91/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.8493 - accuracy: 0.8280 - val_loss: 0.8064 - val_accuracy: 0.8407\n",
            "Epoch 92/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.8334 - accuracy: 0.8305 - val_loss: 0.7942 - val_accuracy: 0.8410\n",
            "Epoch 93/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.8210 - accuracy: 0.8328 - val_loss: 0.7763 - val_accuracy: 0.8453\n",
            "Epoch 94/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.8012 - accuracy: 0.8361 - val_loss: 0.7590 - val_accuracy: 0.8500\n",
            "Epoch 95/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.7818 - accuracy: 0.8405 - val_loss: 0.7319 - val_accuracy: 0.8540\n",
            "Epoch 96/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.7632 - accuracy: 0.8444 - val_loss: 0.7163 - val_accuracy: 0.8570\n",
            "Epoch 97/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.7459 - accuracy: 0.8462 - val_loss: 0.6902 - val_accuracy: 0.8660\n",
            "Epoch 98/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.7244 - accuracy: 0.8528 - val_loss: 0.6813 - val_accuracy: 0.8649\n",
            "Epoch 99/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.7046 - accuracy: 0.8585 - val_loss: 0.6564 - val_accuracy: 0.8700\n",
            "Epoch 100/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6816 - accuracy: 0.8622 - val_loss: 0.6344 - val_accuracy: 0.8756\n",
            "Epoch 101/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6561 - accuracy: 0.8670 - val_loss: 0.6059 - val_accuracy: 0.8809\n",
            "Epoch 102/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6369 - accuracy: 0.8689 - val_loss: 0.5999 - val_accuracy: 0.8827\n",
            "Epoch 103/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.6254 - accuracy: 0.8725 - val_loss: 0.5886 - val_accuracy: 0.8825\n",
            "Epoch 104/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.6183 - accuracy: 0.8730 - val_loss: 0.5815 - val_accuracy: 0.8822\n",
            "Epoch 105/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.6041 - accuracy: 0.8755 - val_loss: 0.5731 - val_accuracy: 0.8838\n",
            "Epoch 106/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.5958 - accuracy: 0.8756 - val_loss: 0.5510 - val_accuracy: 0.8915\n",
            "Epoch 107/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.5760 - accuracy: 0.8797 - val_loss: 0.5302 - val_accuracy: 0.8971\n",
            "Epoch 108/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.5684 - accuracy: 0.8810 - val_loss: 0.5256 - val_accuracy: 0.8952\n",
            "Epoch 109/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.5637 - accuracy: 0.8825 - val_loss: 0.5171 - val_accuracy: 0.8942\n",
            "Epoch 110/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.5404 - accuracy: 0.8868 - val_loss: 0.4996 - val_accuracy: 0.8966\n",
            "Epoch 111/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.5290 - accuracy: 0.8878 - val_loss: 0.4839 - val_accuracy: 0.9035\n",
            "Epoch 112/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.5169 - accuracy: 0.8894 - val_loss: 0.4782 - val_accuracy: 0.9032\n",
            "Epoch 113/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.5047 - accuracy: 0.8915 - val_loss: 0.4667 - val_accuracy: 0.9011\n",
            "Epoch 114/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4917 - accuracy: 0.8924 - val_loss: 0.4600 - val_accuracy: 0.9048\n",
            "Epoch 115/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.4851 - accuracy: 0.8933 - val_loss: 0.4507 - val_accuracy: 0.9037\n",
            "Epoch 116/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4774 - accuracy: 0.8948 - val_loss: 0.4407 - val_accuracy: 0.9022\n",
            "Epoch 117/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4694 - accuracy: 0.8958 - val_loss: 0.4319 - val_accuracy: 0.9061\n",
            "Epoch 118/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.4639 - accuracy: 0.8959 - val_loss: 0.4306 - val_accuracy: 0.9061\n",
            "Epoch 119/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4569 - accuracy: 0.8951 - val_loss: 0.4205 - val_accuracy: 0.9091\n",
            "Epoch 120/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4488 - accuracy: 0.8993 - val_loss: 0.4152 - val_accuracy: 0.9072\n",
            "Epoch 121/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4440 - accuracy: 0.8985 - val_loss: 0.4056 - val_accuracy: 0.9083\n",
            "Epoch 122/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4298 - accuracy: 0.9004 - val_loss: 0.3950 - val_accuracy: 0.9107\n",
            "Epoch 123/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.4231 - accuracy: 0.8994 - val_loss: 0.3863 - val_accuracy: 0.9101\n",
            "Epoch 124/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4143 - accuracy: 0.9029 - val_loss: 0.3832 - val_accuracy: 0.9093\n",
            "Epoch 125/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.4086 - accuracy: 0.9016 - val_loss: 0.3739 - val_accuracy: 0.9115\n",
            "Epoch 126/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4021 - accuracy: 0.9018 - val_loss: 0.3763 - val_accuracy: 0.9115\n",
            "Epoch 127/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3964 - accuracy: 0.9028 - val_loss: 0.3645 - val_accuracy: 0.9120\n",
            "Epoch 128/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3955 - accuracy: 0.9022 - val_loss: 0.3690 - val_accuracy: 0.9123\n",
            "Epoch 129/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4014 - accuracy: 0.9018 - val_loss: 0.3772 - val_accuracy: 0.9088\n",
            "Epoch 130/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4019 - accuracy: 0.9011 - val_loss: 0.3713 - val_accuracy: 0.9088\n",
            "Epoch 131/200\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.4057 - accuracy: 0.9005 - val_loss: 0.3822 - val_accuracy: 0.9101\n",
            "Epoch 132/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4110 - accuracy: 0.9003 - val_loss: 0.3908 - val_accuracy: 0.9072\n",
            "Epoch 133/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4178 - accuracy: 0.8989 - val_loss: 0.3909 - val_accuracy: 0.9083\n",
            "Epoch 134/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.4119 - accuracy: 0.8997 - val_loss: 0.3756 - val_accuracy: 0.9109\n",
            "Epoch 135/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.4069 - accuracy: 0.9000 - val_loss: 0.3778 - val_accuracy: 0.9059\n",
            "Epoch 136/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4087 - accuracy: 0.8995 - val_loss: 0.3726 - val_accuracy: 0.9136\n",
            "Epoch 137/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3956 - accuracy: 0.9006 - val_loss: 0.3553 - val_accuracy: 0.9125\n",
            "Epoch 138/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3906 - accuracy: 0.9016 - val_loss: 0.3543 - val_accuracy: 0.9141\n",
            "Epoch 139/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3783 - accuracy: 0.9030 - val_loss: 0.3406 - val_accuracy: 0.9107\n",
            "Epoch 140/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3657 - accuracy: 0.9040 - val_loss: 0.3297 - val_accuracy: 0.9131\n",
            "Epoch 141/200\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 0.3596 - accuracy: 0.9054 - val_loss: 0.3286 - val_accuracy: 0.9136\n",
            "Epoch 142/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3533 - accuracy: 0.9050 - val_loss: 0.3168 - val_accuracy: 0.9149\n",
            "Epoch 143/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3452 - accuracy: 0.9052 - val_loss: 0.3135 - val_accuracy: 0.9173\n",
            "Epoch 144/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3376 - accuracy: 0.9082 - val_loss: 0.3099 - val_accuracy: 0.9147\n",
            "Epoch 145/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3353 - accuracy: 0.9041 - val_loss: 0.3050 - val_accuracy: 0.9168\n",
            "Epoch 146/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3372 - accuracy: 0.9052 - val_loss: 0.3059 - val_accuracy: 0.9168\n",
            "Epoch 147/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3330 - accuracy: 0.9062 - val_loss: 0.3020 - val_accuracy: 0.9173\n",
            "Epoch 148/200\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.3318 - accuracy: 0.9065 - val_loss: 0.3036 - val_accuracy: 0.9139\n",
            "Epoch 149/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3297 - accuracy: 0.9066 - val_loss: 0.2988 - val_accuracy: 0.9162\n",
            "Epoch 150/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3237 - accuracy: 0.9075 - val_loss: 0.2941 - val_accuracy: 0.9139\n",
            "Epoch 151/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3222 - accuracy: 0.9070 - val_loss: 0.2892 - val_accuracy: 0.9194\n",
            "Epoch 152/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3191 - accuracy: 0.9070 - val_loss: 0.2893 - val_accuracy: 0.9173\n",
            "Epoch 153/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3178 - accuracy: 0.9060 - val_loss: 0.2879 - val_accuracy: 0.9168\n",
            "Epoch 154/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3143 - accuracy: 0.9063 - val_loss: 0.2858 - val_accuracy: 0.9181\n",
            "Epoch 155/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3112 - accuracy: 0.9072 - val_loss: 0.2806 - val_accuracy: 0.9157\n",
            "Epoch 156/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3081 - accuracy: 0.9072 - val_loss: 0.2786 - val_accuracy: 0.9192\n",
            "Epoch 157/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3053 - accuracy: 0.9064 - val_loss: 0.2777 - val_accuracy: 0.9186\n",
            "Epoch 158/200\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.3038 - accuracy: 0.9077 - val_loss: 0.2776 - val_accuracy: 0.9168\n",
            "Epoch 159/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.3025 - accuracy: 0.9079 - val_loss: 0.2722 - val_accuracy: 0.9186\n",
            "Epoch 160/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3016 - accuracy: 0.9066 - val_loss: 0.2740 - val_accuracy: 0.9162\n",
            "Epoch 161/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3020 - accuracy: 0.9074 - val_loss: 0.2729 - val_accuracy: 0.9189\n",
            "Epoch 162/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.3000 - accuracy: 0.9064 - val_loss: 0.2722 - val_accuracy: 0.9173\n",
            "Epoch 163/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3031 - accuracy: 0.9064 - val_loss: 0.2765 - val_accuracy: 0.9173\n",
            "Epoch 164/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3071 - accuracy: 0.9067 - val_loss: 0.2775 - val_accuracy: 0.9181\n",
            "Epoch 165/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3120 - accuracy: 0.9059 - val_loss: 0.2777 - val_accuracy: 0.9173\n",
            "Epoch 166/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3149 - accuracy: 0.9052 - val_loss: 0.2901 - val_accuracy: 0.9141\n",
            "Epoch 167/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3262 - accuracy: 0.9034 - val_loss: 0.3018 - val_accuracy: 0.9117\n",
            "Epoch 168/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3462 - accuracy: 0.9014 - val_loss: 0.3162 - val_accuracy: 0.9152\n",
            "Epoch 169/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3649 - accuracy: 0.8976 - val_loss: 0.3312 - val_accuracy: 0.9099\n",
            "Epoch 170/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.3856 - accuracy: 0.8938 - val_loss: 0.3416 - val_accuracy: 0.9075\n",
            "Epoch 171/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4266 - accuracy: 0.8856 - val_loss: 0.4344 - val_accuracy: 0.8865\n",
            "Epoch 172/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4552 - accuracy: 0.8809 - val_loss: 0.4015 - val_accuracy: 0.8942\n",
            "Epoch 173/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.4451 - accuracy: 0.8830 - val_loss: 0.3805 - val_accuracy: 0.8992\n",
            "Epoch 174/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.4221 - accuracy: 0.8858 - val_loss: 0.3626 - val_accuracy: 0.9051\n",
            "Epoch 175/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3910 - accuracy: 0.8931 - val_loss: 0.3218 - val_accuracy: 0.9101\n",
            "Epoch 176/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.3541 - accuracy: 0.8997 - val_loss: 0.2999 - val_accuracy: 0.9168\n",
            "Epoch 177/200\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.3293 - accuracy: 0.9032 - val_loss: 0.2807 - val_accuracy: 0.9160\n",
            "Epoch 178/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.3081 - accuracy: 0.9068 - val_loss: 0.2687 - val_accuracy: 0.9162\n",
            "Epoch 179/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.3007 - accuracy: 0.9064 - val_loss: 0.2641 - val_accuracy: 0.9200\n",
            "Epoch 180/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2928 - accuracy: 0.9058 - val_loss: 0.2592 - val_accuracy: 0.9200\n",
            "Epoch 181/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2891 - accuracy: 0.9067 - val_loss: 0.2566 - val_accuracy: 0.9168\n",
            "Epoch 182/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2858 - accuracy: 0.9074 - val_loss: 0.2534 - val_accuracy: 0.9184\n",
            "Epoch 183/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2830 - accuracy: 0.9067 - val_loss: 0.2516 - val_accuracy: 0.9192\n",
            "Epoch 184/200\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 0.2811 - accuracy: 0.9078 - val_loss: 0.2515 - val_accuracy: 0.9128\n",
            "Epoch 185/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2782 - accuracy: 0.9081 - val_loss: 0.2458 - val_accuracy: 0.9232\n",
            "Epoch 186/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.2778 - accuracy: 0.9074 - val_loss: 0.2506 - val_accuracy: 0.9173\n",
            "Epoch 187/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.2774 - accuracy: 0.9075 - val_loss: 0.2468 - val_accuracy: 0.9208\n",
            "Epoch 188/200\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.2754 - accuracy: 0.9063 - val_loss: 0.2452 - val_accuracy: 0.9216\n",
            "Epoch 189/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.2736 - accuracy: 0.9063 - val_loss: 0.2467 - val_accuracy: 0.9162\n",
            "Epoch 190/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2734 - accuracy: 0.9071 - val_loss: 0.2453 - val_accuracy: 0.9162\n",
            "Epoch 191/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.2716 - accuracy: 0.9071 - val_loss: 0.2458 - val_accuracy: 0.9147\n",
            "Epoch 192/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2708 - accuracy: 0.9070 - val_loss: 0.2452 - val_accuracy: 0.9173\n",
            "Epoch 193/200\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 0.2708 - accuracy: 0.9069 - val_loss: 0.2404 - val_accuracy: 0.9213\n",
            "Epoch 194/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2720 - accuracy: 0.9068 - val_loss: 0.2426 - val_accuracy: 0.9205\n",
            "Epoch 195/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2703 - accuracy: 0.9077 - val_loss: 0.2406 - val_accuracy: 0.9192\n",
            "Epoch 196/200\n",
            "25/25 [==============================] - 4s 173ms/step - loss: 0.2694 - accuracy: 0.9072 - val_loss: 0.2420 - val_accuracy: 0.9194\n",
            "Epoch 197/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.2709 - accuracy: 0.9073 - val_loss: 0.2404 - val_accuracy: 0.9192\n",
            "Epoch 198/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2709 - accuracy: 0.9078 - val_loss: 0.2421 - val_accuracy: 0.9154\n",
            "Epoch 199/200\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.2689 - accuracy: 0.9077 - val_loss: 0.2376 - val_accuracy: 0.9170\n",
            "Epoch 200/200\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2686 - accuracy: 0.9075 - val_loss: 0.2402 - val_accuracy: 0.9202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87144bfcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "buFYOxefcSMe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/accuracy_nlp-next_word.h5')"
      ],
      "metadata": {
        "id": "FKb_36MZiloG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"Alice could see, as well\""
      ],
      "metadata": {
        "id": "2DLJY2Qtilz1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_to_seq = tokenizer.texts_to_sequences([text])[0]"
      ],
      "metadata": {
        "id": "mw4yJjTgil-7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_to_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X41vIIAximKJ",
        "outputId": "030c1166-e750-4bd1-e7d2-131936e5effc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[66, 2, 58, 11, 4, 51, 110]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding = pad_sequences([t_to_seq],maxlen=15,padding='pre')"
      ],
      "metadata": {
        "id": "MKMduraFimZf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUcqHpLbimts",
        "outputId": "533c99aa-088c-427b-8bb9-07596b79d2f9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,  66,   2,  58,  11,   4,\n",
              "         51, 110]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted = model.predict_classes(padding)\n",
        "# x=np.argmax(predicted,axis=1)\n",
        "predict = np.argmax(model.predict(padding), axis=-1)"
      ],
      "metadata": {
        "id": "yBQbYtKPkczT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WFQ-80wmOBE",
        "outputId": "b3fdc7ef-d67a-48e4-a617-edbe5a419ffd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "i2B-bD-Ykc_m",
        "outputId": "fe04c3a2-09d8-4602-968a-0460759a5423"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2067b7a095d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'word_to_index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = None\n",
        "for word , index in tokenizer.word_index.items():\n",
        "  if  index == predict:\n",
        "    output = word\n",
        "    break\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5SkR1xEkdLg",
        "outputId": "c9d3b8bf-ba55-4b13-b64e-d0218d9aadb4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "such\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = ''\n",
        "for _ in range(20):\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "    padding = pad_sequences([token_list],maxlen=15, padding='pre')\n",
        "    predicted = predict = np.argmax(model.predict(padding), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    text += \" \" + output_word\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKjdYzdZkdWF",
        "outputId": "c84b467f-b47d-4a9d-c824-2b462b5fbd52"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice could see, as well as if she were looking over their sleep she felt two if the caterpillar was there had quite the way it's in their names were in their table with the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In another moment down went Alice after it, never once\n",
        "# considering how in the world she was to get out again."
      ],
      "metadata": {
        "id": "r4IJIDpWkdhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.layers[0].get_weights()[0]\n",
        "embeddings[60]"
      ],
      "metadata": {
        "id": "jMxyWUnxkdsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8928521-9636-44c5-e2b4-3f7e30e5a00f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.08344252,  0.00510313, -0.17960808, -0.03472053, -0.10028249,\n",
              "        0.0691199 , -0.03117628,  0.09111877,  0.03555365, -0.12193644,\n",
              "       -0.10330232,  0.06596287,  0.03676869, -0.07250361, -0.03804107,\n",
              "        0.05481109, -0.0142484 ,  0.21630506, -0.01342051,  0.1022603 ,\n",
              "       -0.02084466,  0.00445812, -0.13012843,  0.02257405,  0.13256058,\n",
              "        0.04733593, -0.06337781, -0.07571854,  0.06618419,  0.11430182,\n",
              "       -0.07963777,  0.10212055, -0.02632232, -0.03299565,  0.0067985 ,\n",
              "        0.07192999, -0.10378733, -0.13070299,  0.08883631, -0.13576822,\n",
              "        0.03922619,  0.08726501,  0.00383673,  0.04288139, -0.04299189,\n",
              "       -0.00259255,  0.13386863,  0.00549963, -0.18601252,  0.0454355 ,\n",
              "        0.06126179, -0.00191975, -0.09429233,  0.00603326,  0.05206077,\n",
              "       -0.11694278, -0.11521396, -0.05419602, -0.03972219,  0.12855276,\n",
              "        0.05615821,  0.06818191,  0.07098094, -0.03255486,  0.00133745,\n",
              "       -0.01245874,  0.04858655, -0.11350741,  0.1132172 , -0.13539413,\n",
              "       -0.03793769, -0.04433741, -0.02930554,  0.01341312,  0.05126368,\n",
              "       -0.00084397,  0.19362149, -0.15816416,  0.1171656 ,  0.06192886,\n",
              "        0.10951229, -0.15071663, -0.0383017 , -0.02460459,  0.09036897,\n",
              "       -0.05937023, -0.11966552, -0.09275423,  0.12684295,  0.01773509,\n",
              "       -0.08742426, -0.03885389,  0.02988808, -0.04973865, -0.11459361,\n",
              "       -0.11570063, -0.06400814, -0.02156912,  0.11021501,  0.06940519,\n",
              "       -0.08652592,  0.06092779,  0.0705791 ,  0.01284493, -0.06324062,\n",
              "        0.28710026,  0.06801718,  0.08797936, -0.03280465, -0.00602453,\n",
              "        0.07475794,  0.04615072,  0.05216249, -0.1472949 , -0.1320509 ,\n",
              "       -0.11002211,  0.06263862, -0.03909419,  0.00814988, -0.06182448,\n",
              "       -0.24784118, -0.05667668,  0.0991184 ,  0.12496673, -0.0063881 ,\n",
              "        0.1743517 ,  0.01598193, -0.03915339,  0.01735694, -0.0046223 ,\n",
              "       -0.04918533,  0.04282648,  0.18822552, -0.01464952,  0.10250583,\n",
              "        0.06560837, -0.00163145,  0.01206368, -0.00557391, -0.06417318,\n",
              "        0.03304157,  0.05436839,  0.01914444, -0.0205441 ,  0.0834219 ,\n",
              "       -0.04353235, -0.06129211, -0.05703827,  0.00988285, -0.09872255,\n",
              "       -0.07157683, -0.04141291,  0.0529704 ,  0.27693704,  0.03343006,\n",
              "       -0.11546613,  0.13959688, -0.09038077, -0.00701046, -0.02277416,\n",
              "        0.03076107, -0.01188304,  0.18141767,  0.05740384, -0.00446912,\n",
              "        0.02523933,  0.00149872,  0.04446834,  0.22664136, -0.02435578,\n",
              "       -0.01838966, -0.05566001, -0.05366086, -0.19314857, -0.05057337,\n",
              "       -0.00854386, -0.01835531, -0.04201337,  0.05526082,  0.02655211,\n",
              "       -0.07237166, -0.01378128, -0.05178431,  0.00073608,  0.03767649,\n",
              "        0.06589345, -0.08760619,  0.18553951, -0.12806614, -0.0557668 ,\n",
              "        0.16942842,  0.06867614, -0.06086272,  0.03116203, -0.07103113,\n",
              "        0.00552387, -0.04207399,  0.02242012, -0.06708734,  0.06502174,\n",
              "        0.02071831,  0.07436632,  0.20640548,  0.06331443,  0.00461905,\n",
              "        0.10938421, -0.03623825,  0.03971923,  0.04417011,  0.02722297,\n",
              "        0.19807883,  0.01253137, -0.05991087, -0.08570048,  0.0084076 ,\n",
              "        0.14003459,  0.01313618,  0.07315411, -0.04137789, -0.07903305,\n",
              "       -0.04511982,  0.07034375, -0.0221334 , -0.0407671 , -0.01771962,\n",
              "       -0.01654802,  0.24968693, -0.03928982,  0.0904681 ,  0.06831876,\n",
              "        0.0543754 ,  0.04884835,  0.02786894,  0.05584022, -0.06533837,\n",
              "       -0.02683816,  0.06524035, -0.07691702,  0.10941375, -0.08050526,\n",
              "       -0.09245791, -0.03014819, -0.03530163, -0.03385776,  0.10804585,\n",
              "       -0.05691388,  0.05059828,  0.11113271, -0.12805389,  0.03892957,\n",
              "       -0.02228192, -0.19195396, -0.03753125,  0.08362588, -0.07589919,\n",
              "        0.00682038,  0.03047022, -0.0187635 , -0.01450906,  0.12032355,\n",
              "        0.07669859,  0.06687617,  0.03057845, -0.04013042,  0.07189566,\n",
              "       -0.09546326, -0.00597171, -0.08298695, -0.04259714,  0.03114911,\n",
              "        0.08772217, -0.03082772,  0.07926711, -0.03811307, -0.02190695,\n",
              "        0.06310205, -0.04676566,  0.02691792, -0.03655645, -0.12858623,\n",
              "        0.02928034,  0.09561563, -0.01649579,  0.04462262, -0.05225298,\n",
              "        0.04268735, -0.04204741,  0.11473688, -0.0801875 , -0.1022423 ,\n",
              "       -0.02087348,  0.06386532,  0.11518124, -0.06275874,  0.05094626,\n",
              "        0.06749278, -0.03023354, -0.01812905, -0.04040421, -0.1173916 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/51235118/how-to-get-word-vectors-from-keras-embedding-layer"
      ],
      "metadata": {
        "id": "csRQtybjUuaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "em = {index : embeddings[index]  for word , index in tokenizer.word_index.items()}"
      ],
      "metadata": {
        "id": "zkopfzUOUwNA"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(em[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvE_N5buYaow",
        "outputId": "928bef18-c3ae-4c15-fc65-a468cbd5b6b0"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "em['feel']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KCQ-_umXlRJ",
        "outputId": "f79a8eeb-d3b0-44fd-cb21-499a8ddbe63a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.43014854e-02,  9.03913081e-02, -4.69314717e-02, -1.19568761e-02,\n",
              "        3.50401960e-02,  4.88642789e-02, -5.29776216e-02,  2.47012135e-02,\n",
              "        1.08202640e-02,  6.11497648e-02,  1.23267673e-01, -1.09883837e-01,\n",
              "        2.59629115e-02, -7.69578665e-02,  1.10376161e-02, -4.87868823e-02,\n",
              "        4.57184874e-02, -6.90467507e-02, -7.18417764e-02,  5.19953035e-02,\n",
              "       -3.26016173e-02,  5.97062595e-02, -3.76308151e-02,  1.27445664e-02,\n",
              "        1.18338346e-01, -1.08736888e-01, -2.06767842e-02, -9.19770729e-03,\n",
              "        1.45420969e-01,  6.94157481e-02, -1.93400923e-02,  3.49471439e-03,\n",
              "        2.00287580e-01,  9.43972990e-02,  1.56609908e-01, -7.89398849e-02,\n",
              "        3.23599651e-02, -4.25755978e-02,  4.50995117e-02, -8.08374360e-02,\n",
              "       -1.72068268e-01, -1.64860114e-02,  6.56236187e-02, -1.14026368e-01,\n",
              "        9.23725665e-02, -9.16553214e-02,  2.13897619e-02, -6.64447770e-02,\n",
              "        1.86054204e-02, -2.54221000e-02, -4.06147763e-02,  8.64942968e-02,\n",
              "       -1.69790536e-01, -7.34440759e-02,  1.52377352e-01,  3.73637304e-02,\n",
              "        5.60988039e-02,  7.92469233e-02,  5.96059225e-02,  1.02111086e-01,\n",
              "       -1.41461641e-01, -2.74315998e-02, -6.96725324e-02, -5.33513539e-03,\n",
              "       -2.63244938e-02, -2.43658163e-02,  9.69457701e-02,  6.99063018e-02,\n",
              "        1.20267078e-01, -8.10755342e-02,  8.10633898e-02,  8.00586939e-02,\n",
              "       -6.70745075e-02,  1.45260263e-02,  5.08778878e-02,  3.66191864e-02,\n",
              "       -2.17152815e-02,  2.43534446e-02, -3.59841138e-02, -3.82906683e-02,\n",
              "        6.20892867e-02, -2.71832163e-04, -4.88578938e-02,  8.42549056e-02,\n",
              "        5.86659461e-03, -5.06537221e-02, -1.46253556e-01, -7.88638815e-02,\n",
              "       -2.47233547e-02, -1.63899809e-01, -2.95028705e-02,  2.21347082e-02,\n",
              "        5.34597747e-02, -1.22161612e-01,  5.06168716e-02, -7.03191534e-02,\n",
              "        1.59757305e-02,  1.68220207e-01,  3.67709883e-02, -4.97931577e-02,\n",
              "        2.37849340e-01,  1.56413987e-02, -9.11414102e-02,  2.55129933e-02,\n",
              "        1.62621941e-02,  1.63072467e-01, -9.13047194e-02,  2.69007832e-01,\n",
              "       -1.02988081e-02,  1.39411062e-01, -7.49011263e-02,  5.87593624e-03,\n",
              "       -3.55719216e-03, -7.30659738e-02,  7.52978772e-02, -8.65960680e-03,\n",
              "        3.96720245e-02, -1.19823245e-02,  6.89656287e-02,  7.93284178e-02,\n",
              "       -1.18347302e-01, -1.05397783e-01,  3.57163623e-02, -1.52426481e-01,\n",
              "       -9.16570202e-02, -2.19959300e-02, -6.15494959e-02,  1.10520244e-01,\n",
              "        1.22749517e-02, -8.96370485e-02,  1.39096724e-02,  4.95713996e-03,\n",
              "        1.44044146e-01, -2.62555331e-02, -1.41883790e-01,  4.81010452e-02,\n",
              "       -5.55453636e-03,  6.35995194e-02, -8.42890739e-02,  1.09491147e-01,\n",
              "        1.64514743e-02,  4.78644259e-02,  1.23923356e-02,  1.62470177e-01,\n",
              "        8.85404646e-03, -1.26817813e-02, -5.35979830e-02,  7.21245185e-02,\n",
              "       -3.15498039e-02, -4.77605835e-02, -1.14105694e-01, -4.37818374e-03,\n",
              "        4.23399098e-02,  2.02237461e-02,  7.07478374e-02,  8.08527693e-03,\n",
              "       -6.61148280e-02,  5.42392135e-02, -3.07412557e-02, -8.12745094e-03,\n",
              "        2.33774800e-02,  3.13697569e-02, -1.23809781e-02,  2.07717344e-01,\n",
              "        8.47937912e-02,  1.85624659e-02,  2.05334891e-02,  1.67846363e-02,\n",
              "       -3.25909369e-02,  1.21499129e-01,  2.85044797e-02,  3.38551924e-02,\n",
              "        3.06111090e-02, -1.57444119e-01, -1.14536909e-02,  6.02875091e-02,\n",
              "       -3.27411219e-02, -7.71771967e-02,  1.15391731e-01, -4.58551347e-02,\n",
              "       -1.54111320e-02, -6.21844120e-02, -2.17198133e-02, -8.50737318e-02,\n",
              "        3.48856337e-02, -3.05878092e-02, -9.09451619e-02, -8.10474530e-02,\n",
              "        5.62445521e-02, -1.35166928e-01,  1.16215721e-01,  2.38142058e-01,\n",
              "        2.80822869e-02,  8.74947831e-02, -6.47317199e-03, -6.82604462e-02,\n",
              "       -1.22218691e-02, -9.94500611e-03,  1.26587192e-03, -3.71646695e-02,\n",
              "       -1.04950257e-01,  9.94003564e-03, -2.59857327e-01,  4.25611995e-02,\n",
              "       -2.71465722e-02, -3.38294543e-02,  6.09743521e-02, -1.62436202e-01,\n",
              "        3.97660173e-02, -2.73461360e-02,  6.39989832e-03,  4.17363299e-06,\n",
              "       -1.03967026e-01, -7.34903812e-02, -1.01802506e-01, -8.04266706e-02,\n",
              "       -6.84522763e-02,  8.65170732e-02, -1.09883845e-02,  2.25980803e-02,\n",
              "       -2.12709513e-02, -8.71373639e-02,  7.81712756e-02, -9.38692242e-02,\n",
              "       -1.23225160e-01, -5.86123504e-02, -1.02731213e-01,  1.11713052e-01,\n",
              "        6.51288033e-02,  1.11628972e-01,  1.24395117e-02,  7.46649355e-02,\n",
              "        8.41839612e-02, -7.71051049e-02,  1.28016442e-01,  7.61339441e-02,\n",
              "        7.47630000e-02, -5.03892265e-02,  2.61811744e-02, -1.32683277e-01,\n",
              "       -7.45374262e-02, -1.15184098e-01,  4.35017683e-02, -4.45612632e-02,\n",
              "        3.39905843e-02, -5.96069135e-02,  1.27476295e-02, -9.40453634e-03,\n",
              "       -7.18334466e-02, -1.34361342e-01,  2.18764082e-01,  1.28709927e-01,\n",
              "        8.18612613e-03, -6.28973469e-02, -5.30770868e-02,  8.92587900e-02,\n",
              "        2.24335641e-02, -2.30564997e-02,  6.20857766e-03, -2.19228361e-02,\n",
              "        2.07008459e-04, -2.21515790e-01,  4.26697498e-03,  2.54380871e-02,\n",
              "       -2.56703496e-02,  1.73533976e-01,  6.05538161e-03,  6.91830739e-02,\n",
              "       -1.10994922e-02, -1.86345711e-01,  5.57210529e-03, -7.00663254e-02,\n",
              "        2.76294611e-02, -9.92907360e-02, -1.25802875e-01, -6.03770651e-02,\n",
              "        1.24358155e-01,  5.04310876e-02,  2.58084033e-02,  1.48493154e-02,\n",
              "       -1.14948470e-02, -9.59895365e-03,  4.68080007e-02,  1.21392049e-01,\n",
              "        2.74451450e-02, -5.96917886e-03,  4.62204963e-02,  7.53116310e-02,\n",
              "        1.96339399e-01,  2.70792060e-02, -3.11437324e-02,  1.15107410e-01,\n",
              "        9.27019224e-04, -7.32914582e-02,  6.24298118e-02,  6.58436716e-02,\n",
              "       -3.82910483e-02, -2.96731740e-02, -6.82433248e-02, -4.11953107e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "fDOevksEV2dE"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity([em['she']], [em['her']])[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Egj6QHgPWYLn",
        "outputId": "36ce20a5-47b0-4ac9-9af5-ded45ce49411"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1461379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(word):\n",
        "  \n",
        "  cos = [cosine_similarity([em[word]],[em[i+1]]) for i in range(len(em))]\n",
        "  return sorted(cos,key=max)[0]"
      ],
      "metadata": {
        "id": "oQcGxtVmWtZZ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gNQLmb0as9a",
        "outputId": "d4f65024-5d7a-486c-faa4-e99f6b407316"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.8028196]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IS0BhM9-axXz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}